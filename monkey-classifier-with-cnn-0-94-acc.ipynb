{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing","metadata":{}},{"cell_type":"code","source":"# Basic Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n# TensorFlow Libraries\nimport cv2\nfrom tensorflow.keras import models, layers, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import load_img\n\n# Transfer Learning Libraries\nfrom tensorflow.keras.applications import Xception\n\n# Other Libraries\nfrom io import BytesIO\nfrom PIL import Image\nimport requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T23:00:54.324920Z","iopub.execute_input":"2021-12-29T23:00:54.325241Z","iopub.status.idle":"2021-12-29T23:00:58.989676Z","shell.execute_reply.started":"2021-12-29T23:00:54.325150Z","shell.execute_reply":"2021-12-29T23:00:58.988853Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data from each Monkey Species","metadata":{}},{"cell_type":"code","source":"example_images = [\"../input/10-monkey-species/training/training/n0/\"\n, \"../input/10-monkey-species/training/training/n1/\"\n,\"../input/10-monkey-species/training/training/n2/\"\n, \"../input/10-monkey-species/training/training/n3/\"\n, \"../input/10-monkey-species/training/training/n4/\"\n,\"../input/10-monkey-species/training/training/n5/\"\n,\"../input/10-monkey-species/training/training/n6/\"\n,\"../input/10-monkey-species/training/training/n7/\"\n,\"../input/10-monkey-species/training/training/n8/\",\n\"../input/10-monkey-species/training/training/n9/\"]\n\nfig = plt.figure(figsize=(24, 10))\n\nj=1\nfor i in example_images:   \n    filenames  = os.listdir(i)\n    sample = filenames[0]\n    img = load_img(i+sample)\n    plt.subplot(2,5,j)\n    plt.axis(\"equal\")\n    plt.imshow(img)\n    plt.xlabel(\"Monkey Species: n{}\".format(j))\n    j+=1\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T23:00:58.995917Z","iopub.execute_input":"2021-12-29T23:00:58.998945Z","iopub.status.idle":"2021-12-29T23:01:03.269258Z","shell.execute_reply.started":"2021-12-29T23:00:58.998906Z","shell.execute_reply":"2021-12-29T23:01:03.268478Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Preparing the Data for the Model\n\n","metadata":{}},{"cell_type":"code","source":"train_dir = '../input/10-monkey-species/training/training'\nvalidation_dir = '../input/10-monkey-species/validation/validation'\n\nBATCH_SIZE = 8\nIMG_SIZE = (224,224)\n\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range = 30,\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size= BATCH_SIZE,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical')\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T23:01:03.270476Z","iopub.execute_input":"2021-12-29T23:01:03.271057Z","iopub.status.idle":"2021-12-29T23:01:03.499427Z","shell.execute_reply.started":"2021-12-29T23:01:03.271019Z","shell.execute_reply":"2021-12-29T23:01:03.498724Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Base (Transfer Learning) and Head layers","metadata":{}},{"cell_type":"code","source":"Xception_base = Xception(weights='imagenet', \n                         include_top=False)\n\nx = Xception_base.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(512, activation='relu')(x)\n\nsoftmax_output_len =int(len(train_generator.class_indices.keys()))\n\npredictions = layers.Dense(softmax_output_len, activation='softmax')(x)\nXception_transfer = models.Model(inputs=Xception_base.input, outputs=predictions)\n\nXception_transfer.summary()\n\nXception_transfer.compile(loss='categorical_crossentropy',\n                          optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9), \n                          metrics=['accuracy'])\n\nhistory = Xception_transfer.fit(train_generator,\n                                          epochs=10,\n                                          shuffle = True, \n                                          verbose = 1, \n                                          validation_data = validation_generator)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T23:01:03.501575Z","iopub.execute_input":"2021-12-29T23:01:03.502081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of the Accuracy and Loss of the model","metadata":{}},{"cell_type":"code","source":"def history_plot(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylabel('Accuracy')\n    plt.ylim([min(plt.ylim()),1])\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.ylabel('Cross Entropy')\n    plt.ylim([min(val_loss)-0.2,max(loss)+0.2])\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_plot(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Examining Test Data","metadata":{}},{"cell_type":"code","source":"test_images = [\n    \"https://projectzerofootprint.com/wp-content/uploads/2016/08/monkey-2-1080x768.jpg\",\n    \"https://i.ytimg.com/vi/Ptisy32iRRA/hqdefault.jpg\",\n    \"https://images.pond5.com/red-uakari-monkey-footage-064800523_iconl.jpeg\",\n    \"https://thejapanalps.com/wp-content/uploads/2020/03/nihonsaru01.jpg\",\n    \"https://www.zoo-leipzig.de/fileadmin/_processed_/e/c/csm_Weissbauch-Zwergseidenaeffchen_3_c46c37b6a1.jpg\",\n    \"https://cdn.britannica.com/05/181805-050-C9682415/capuchin-monkey.jpg\",\n    \"https://www.neprimateconservancy.org/uploads/1/5/3/8/15380094/silvery-marmoset-istock-153473655-resize_45.jpg\",\n    \"https://study.com/cimages/multimages/16/squirrel_monkeys.png\",\n    \"https://ars.els-cdn.com/content/image/3-s2.0-B9780124095274000171-f17-04-9780124095274.jpg\",\n    \"https://media-cdn.tripadvisor.com/media/photo-s/0a/67/93/f5/nilgiri-langur-karunkorangu.jpg\"\n]\n\ntest_labels = [\"n0\", \"n1\", \"n2\", \n               \"n3\", \"n4\", \"n5\", \n               \"n6\", \"n7\", \n               \"n8\", \"n9\"]\n\nmonkey_speciets_type = [\"Mantled Howler\",\"Patas Monkey\",\"Bald Uakari\",\n                        \"Japanese Macaque\",\"Pygmy Marmoset\",\"White Headed Capuchin\",\n                        \"Silvery Marmoset\",\"Ommon Squirrel Monkey\",\n                        \"Black Headed Night Monkey\",\"Nilgiri Langur\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor (i,label) in enumerate(test_labels):\n    response = requests.get(test_images[i])\n    img = Image.open(BytesIO(response.content))\n    img = np.asarray(img)/255.\n    img = cv2.resize(img, (224,224))\n    prediction=Xception_transfer.predict(img.reshape(1, 224,224,3))\n    output = np.argmax(prediction)\n     \n    plt.title(\"Real: {} \\n Predict: {}\".format(monkey_speciets_type[i], monkey_speciets_type[output]))\n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}